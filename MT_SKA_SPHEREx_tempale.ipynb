{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergies between SKA and SPHEREx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#packages needed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from configobj import ConfigObj\n",
    "from scipy.interpolate import splrep, splev\n",
    "import scipy as sp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "We will use IM of 2 lines:\n",
    "* HI: $\\lambda=21$cm\n",
    "* H$\\alpha$: $\\lambda=656.3$nm\n",
    "\n",
    "We will use two surveys:\n",
    "* SKA1 for HI\n",
    "* SPHEREx for H$\\alpha$\n",
    "\n",
    "## Specs of each survey\n",
    "\n",
    "### SKA1 in single dish mode\n",
    "\n",
    "* Full sky\n",
    "* Noise Power Spectrum: $\\mathcal N^{ HI}_{ij}=\\frac{S_{\\rm area}}{2N_{\\rm d} t_{\\rm tot}}T^2_{\\rm sys}\\left(\\nu\\right)$ with $T_{\\rm sys}=25+60(300\\,{\\rm MHz}/\\nu)^{2.55}\\,\\rm K$. \n",
    "* ~200 dishes\n",
    "* $N_d t_{\\rm tot}=2\\times10^6\\,\\rm hr$\n",
    "* High frequency resolution\n",
    "* Redshift range: z=0-3\n",
    "\n",
    "### SPHEREx-like\n",
    "* full sky\n",
    "* Noise: $C_\\ell^{\\rm noise}=\\sigma^2 (\\nu I_\\nu) \\times \\Omega_{\\rm pixel}$\n",
    "* $\\sigma (\\delta\\nu I_\\nu) \\simeq 1 \\times 10^{−17}$ erg/s/cm$^2$\n",
    "* Angular Resolution: $\\Omega_{\\rm pixel}=6.2\"\\times6.2\"=9.03\\times 10^{-10}$Sr $\\simeq 1 \\times 10^{−9}$Sr\n",
    "* Frequency resolution: $\\lambda/\\Delta\\lambda= 41.5$ for $0.75<\\lambda<4.1\\mu$m\n",
    "* Redshift range: z=0.1-5\n",
    "\n",
    "## Spect for Multitracer\n",
    "\n",
    "* Bins/Redshift Res: Chose $\\delta z$, start at $z=0.2$. Example here for 0.1\n",
    "* Sky coverage: $f_{\\rm sky}=0.75$ (assumed). Sky dependence not studied.\n",
    "* Angular pixel: In the case we have two intensity maps the pixel has to be the same for both. There is no gain of having one with an higher res than the other. Note that repixelizing SPHEREx, i.e., reducing the angular pixel does not change the noise power spectrum. And similarly to the radio. So we can use the pixel from the experiments consistentely. Changing the resolution does not affect the noise power spectrum, only the max available ell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Binning\n",
    "z=np.arange(0.2,3,0.1) #chose binning\n",
    "\n",
    "sigma_z=0.05\n",
    "#top hat window with good smoothing\n",
    "smooth=0.01\n",
    "\n",
    "#Ha details. Link to file\n",
    "ha_details=\n",
    "\n",
    "z_Ha=np.loadtxt(ha_details)[:,0]\n",
    "b_Ha_raw=np.loadtxt(ha_details)[:,2]\n",
    "nuI_Ha_raw=np.loadtxt(ha_details)[:,1]\n",
    "c=2.998e8\n",
    "nu_ha=c/(656.3*1e-9*(1+z_Ha))\n",
    "I_Ha_raw=nuI_Ha_raw/nu_ha\n",
    "\n",
    "#HI details. Link to file\n",
    "hi_details=\n",
    "z_hi=np.loadtxt(hi_details)[:,0]\n",
    "b_hi_raw=np.loadtxt(hi_details)[:,2]\n",
    "T_hi_raw=np.loadtxt(hi_details)[:,3]\n",
    "\n",
    "def from_raw_to_surv(z_raw,q_raw,new_z):\n",
    "    rep=splrep(z_raw,q_raw)\n",
    "    return splev(new_z,rep)\n",
    "    \n",
    "bHa=np.around(from_raw_to_surv(z_Ha,b_Ha_raw,z),3)\n",
    "#in erg/s/cm^2/Hz/Sr\n",
    "IHa=from_raw_to_surv(z_Ha,I_Ha_raw,z)\n",
    "bHI=np.around(from_raw_to_surv(z_hi,b_hi_raw,z),3)\n",
    "#in mK\n",
    "THI=from_raw_to_surv(z_hi,T_hi_raw,z)\n",
    "\n",
    "s_IM=0.4\n",
    "\n",
    "## Numbers\n",
    "nT=2\n",
    "nw=len(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(z,bHI,'b-',label=r'$b^{HI}_G$')\n",
    "plt.plot(z,bHa,'r-',lw=3,label=r'$b^{H\\alpha}_G$')\n",
    "plt.plot(z,bHa/bHI,'k--',label=r'$b^{H\\alpha}_G/b^{HI}_G$')\n",
    "plt.xlabel(r'$z$',fontsize=14)\n",
    "plt.ylabel(r'Bias',fontsize=14)\n",
    "plt.legend(loc=2,fontsize=12,frameon=False)\n",
    "plt.savefig('bias_HI_Halpha.pdf')\n",
    "plt.show()\n",
    "plt.plot(z,THI,label=r'$HI$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(z,IHa,label=r'$H\\alpha$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write ini file\n",
    "cs_folder='' #where template ini file of CAMB_sources is. In example file is called template.\n",
    "file_isw_MT=''+'_root.ini' #name you want to give\n",
    "\n",
    "os.system('cp '+cs_folder+'template.ini '+file_isw_MT)\n",
    "\n",
    "inifile = ConfigObj(file_isw_MT)\n",
    "\n",
    "inifile['output_root']= ''\n",
    "inifile['l_max_scalar']= str(600)\n",
    "inifile['accuracy_boost']= str(2)\n",
    "inifile['l_accuracy_boost']= str(2)\n",
    "inifile['l_sample_boost']= str(2)\n",
    "\n",
    "inifile['counts_density']='T' \n",
    "inifile['counts_density_newt']='T' \n",
    "inifile['counts_redshift']= 'T'\n",
    "inifile['DoRedshiftLensing']='F'\n",
    "inifile['counts_radial']= 'F'\n",
    "inifile['counts_timedelay']= 'F' \n",
    "inifile['counts_ISW']= 'T'\n",
    "inifile['counts_velocity']= 'T'\n",
    "inifile['counts_potential']= 'T' \n",
    "inifile['counts_evolve']= 'T'\n",
    "\n",
    "inifile['num_redshiftwindows']=str(nw*nT)\n",
    "for i in range(nw):\n",
    "    #first HI Im\n",
    "    inifile['redshift('+str(i+1)+')']= str(z[i])\n",
    "    inifile['redshift_sigma('+str(i+1)+')']= str(sigma_z)\n",
    "    inifile['redshift_kind('+str(i+1)+')']= 'counts'\n",
    "    inifile['redshift_wintype('+str(i+1)+')']= 'smooth_tophat'\n",
    "    inifile['redshift_smooth('+str(i+1)+')']= str(smooth)\n",
    "    inifile['redshift_bias('+str(i+1)+')']= str(bHI[i])\n",
    "    inifile['redshift_dlog10Ndm('+str(i+1)+')']= str(0.4)\n",
    "    inifile['redshift_dNdz('+str(i+1)+')']= 'hiim'\n",
    "\n",
    "for i in range(nw):\n",
    "    #second Halpha IM\n",
    "    inifile['redshift('+str(nw+i+1)+')']= str(z[i])\n",
    "    inifile['redshift_sigma('+str(nw+i+1)+')']= str(sigma_z)\n",
    "    inifile['redshift_kind('+str(nw+i+1)+')']= 'counts'\n",
    "    inifile['redshift_wintype('+str(nw+i+1)+')']= 'smooth_tophat'\n",
    "    inifile['redshift_smooth('+str(nw+i+1)+')']= str(smooth)\n",
    "    inifile['redshift_bias('+str(nw+i+1)+')']= str(bHa[i])\n",
    "    inifile['redshift_dlog10Ndm('+str(nw+i+1)+')']= str(0.4)\n",
    "    inifile['redshift_dNdz('+str(nw+i+1)+')']= 'halpha'\n",
    "    \n",
    "inifile.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise of each survey\n",
    "\n",
    "### H$\\alpha$ with Spherex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_spherex=1e-9 #Sr\n",
    "#flux sensitivity\n",
    "sign_dnuI_spherex=1e-17 #erg/s/cm^2\n",
    "#per Hz\n",
    "dnu_spherex=nu_ha/41.5\n",
    "#frequency size of the bin\n",
    "Delta_nu_bin_halpha=1e9*c/(656.3)*(1/(1+z-sigma_z)-1/(1+z+sigma_z))\n",
    "#the noise C_\\ell\n",
    "cl_noise_spherex=(sign_dnuI_spherex)**2/pix_spherex/from_raw_to_surv(z_Ha,dnu_spherex,z)/Delta_nu_bin_halpha #erg^2/s^2/cm^4/ Sr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HI with SKA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Delta_nu_bin_hi=1420.4*1e6*(1/(1+z-sigma_z)-1/(1+z+sigma_z))\n",
    "nu_hi=1420.4/(1+z)#Mhz\n",
    "T2_sys=((25 + 60*(300/nu_hi)**2.55)*1e3)**2 #mK^2\n",
    "Ndttot = 2e6*3600 #s\n",
    "N_IM_no_sky=2.0*np.pi*T2_sys/(Ndttot*Delta_nu_bin_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "I_Ha_bin=IHa\n",
    "print(I_Ha_bin)\n",
    "Norm=np.ones((nT*nw,nT*nw))\n",
    "Norm[0:nw,0:nw]=np.array([THI]).T*THI\n",
    "Norm[0:nw,nw:]=np.array([THI]).T*I_Ha_bin\n",
    "Norm[nw:,0:nw]=Norm[0:nw,nw:].T\n",
    "Norm[nw:,nw:]=np.array([I_Ha_bin]).T*I_Ha_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z,I_Ha_bin**2/cl_noise_spherex,'ko')\n",
    "plt.plot(z,THI**2/(N_IM_no_sky*0.75),'b*')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters in the fisher matrix\n",
    "\n",
    "The natural ones would be what we want to measure or diferentiate\n",
    "* $f_{\\rm NL}$\n",
    "* $\\epsilon_{\\rm Doppler}$\n",
    "* $\\epsilon_{\\rm SW}$\n",
    "* $\\epsilon_{\\rm ISW}$\n",
    "\n",
    "The others would be the normal cosmological parameters $\\vartheta={\\ln H_0,\\ln A_s,\\ln n_s,\\ln \\Omega_{CDM},\\ln \\Omega_{b},w}$. We will marginalise over all the bias.\n",
    "\n",
    "The fiducial are $H_0=67,74$ km/s/Mpc, $A_s=2.142 \\times 10^{−9}$, $n_s=0.967$, $\\Omega_{CDM}=0.26$,  $\\Omega_{b}=0.05$,$w=-1$, $f_{\\rm NL}=0$, $\\epsilon_{\\rm GR}=1$ and $\\epsilon_{\\rm ISW}=1$.\n",
    "\n",
    "\n",
    "## Load the angular power spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='' #folder where the files are\n",
    "root=''  #root name of all files needed for this bin\n",
    "parametername=['Ocdm','ns','Ob','w','H0','fnl','eISW','edoppler','eSW']\n",
    "for i in range(0,nw):\n",
    "    parametername=parametername+['bhi'+str(i+1)]\n",
    "for i in range(0,nw):\n",
    "    parametername=parametername+['bha'+str(i+1)]\n",
    "print(parametername)\n",
    "\n",
    "fid_norm=[0.26,0.9667,0.05,1,67.74,1.27,1,1,1]+[1]*nT*nw\n",
    "#fnl multiplied by 1.27 for the CMB convention\n",
    "pars=['As']+parametername"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_fisher={}\n",
    "### Cut the first bin\n",
    "\n",
    "var_fisher['l']=np.arange(2,501)\n",
    "var_fisher['fid']=np.loadtxt(folder+root+'fid_Cl.dat')[:,1:]\n",
    "var_fisher['As']=var_fisher['fid']\n",
    "for i in range(len(parametername)):\n",
    "    var_fisher[parametername[i]]=np.loadtxt(folder+root+parametername[i]+'_dCl.dat')[:,1:]*fid_norm[i]\n",
    "\n",
    "klass = type('Cls', (object,), var_fisher)\n",
    "Cls_ISW_HI_Halpha = klass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Compute the Fisher Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def H(z):\n",
    "    return 67.74*(0.31*(1+z)**3+0.69)**0.5\n",
    "#in Km/s/Mpc\n",
    "\n",
    "def chi(z):\n",
    "    chiev=np.zeros(len(z))\n",
    "    for i in range(len(z)):\n",
    "        zinte=np.arange(0,z[i],0.001)\n",
    "        chiev[i]=np.trapz(c*1e-3/H(zinte),zinte)\n",
    "    return chiev\n",
    "#Max ell that is linear\n",
    "ell_bin_max=np.append(np.around(0.2*0.67*(1+z)**(2/(2+0.967))*chi(z),0),\n",
    "                   np.around(0.2*0.67*(1+z)**(2/(2+0.967))*chi(z),0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fisher_fsky_l(Cls_mtr,fsky,lmin,lmax,norm,N_IM_no_sky,cl_noise_spherex,ell_bin_max,pars,windows,\n",
    "                  tracers,noise_level=1,use_cut=False,cut=[]):\n",
    "    bins=windows*tracers\n",
    "    cut_or=np.arange(0,bins)\n",
    "    npars=len(pars)\n",
    "    fisher=np.zeros((npars,npars))\n",
    "    if lmin<2:\n",
    "        lmin=2\n",
    "    l_range=np.arange(lmin-2,lmax-1,1)\n",
    "    Noise=np.zeros((windows*tracers,windows*tracers))    \n",
    "    Noise[0:windows,0:windows]=np.diag(N_IM_no_sky*fsky)\n",
    "    Noise[windows:,windows:]=np.diag(cl_noise_spherex)\n",
    "    \n",
    "    \n",
    "    for k in l_range:\n",
    "        if use_cut==True:\n",
    "            cut=cut\n",
    "        else:\n",
    "            cut_index=(ell_bin_max>k)\n",
    "            cut=cut_or[cut_index]\n",
    "        temp=np.zeros((npars,npars))\n",
    "        #eigvals, Umatrix=sp.linalg.eigh((Cls_mtr.fid[k,:].reshape(bins,bins)*norm+Noise*noise_level)[cut,:][:,cut])\n",
    "        #Triag, Z=sp.linalg.schur((Cls_mtr.fid[k,:].reshape(bins,bins)*norm+Noise*noise_level)[cut,:][:,cut])\n",
    "        invGamma=sp.linalg.inv((Cls_mtr.fid[k,:].reshape(bins,bins)*norm+Noise*noise_level)[cut,:][:,cut])\n",
    "        #invGamma=np.dot(np.dot(Umatrix,np.diag(1/eigvals)),sp.linalg.inv(Umatrix))\n",
    "        #invGamma=np.dot(Z,np.dot(sp.linalg.inv(Triag),Z.T))\n",
    "        #all methods are equivalent\n",
    "        for i in range(npars):\n",
    "            dcl1=((getattr(Cls_mtr, pars[i])[k,:].reshape(bins,bins)*norm))[cut,:][:,cut]\n",
    "            for j in range(npars):\n",
    "                if j<i:\n",
    "                    next                  \n",
    "                dcl2=((getattr(Cls_mtr, pars[j])[k,:].reshape(bins,bins)*norm))[cut,:][:,cut]\n",
    "                temp[i,j]=np.trace(dcl1.dot(invGamma.dot(dcl2.dot(invGamma))))\n",
    "                temp[j,i]=temp[i,j]\n",
    "        \n",
    "        fisher=fisher+(2*Cls_mtr.l[k]+1)*temp\n",
    "    \n",
    "    fisher=fisher*fsky/2.0\n",
    "    return fisher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sky overlaps\n",
    "f_sky=[0.5,0.75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single tracer\n",
    "\n",
    "### SKA only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fsky in f_sky:\n",
    "    print('Sky Area:', fsky)\n",
    "    lmin_obs=int(np.pi/np.sqrt(4*np.pi*fsky))+1\n",
    "    fisher_IM_HI_Ha=fisher_fsky_l(Cls_ISW_HI_Halpha,fsky,lmin_obs,300,Norm,N_IM_no_sky,cl_noise_spherex,\n",
    "                              ell_bin_max,pars[:-nw],nw,2,noise_level=1,use_cut=True,cut=np.arange(0,nw))\n",
    "    sigma2_IM_HI_Ha=np.linalg.inv(fisher_IM_HI_Ha)\n",
    "    print('sigma :','Marginal','Conditional')\n",
    "    for i in range(len(pars[:-nw])):\n",
    "        sig_epsISW_IM_HI_Ha=np.sqrt(sigma2_IM_HI_Ha[i,i])\n",
    "        print(pars[i]+':',sig_epsISW_IM_HI_Ha,',',np.sqrt(1/fisher_IM_HI_Ha[i,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPHEREx only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_Ha=pars[:-(2*nw)]+pars[-nw:]\n",
    "for fsky in f_sky:\n",
    "    print('Sky Area:', fsky)\n",
    "    lmin_obs=int(np.pi/np.sqrt(4*np.pi*fsky))+1\n",
    "    fisher_IM_HI_Ha=fisher_fsky_l(Cls_ISW_HI_Halpha,fsky,lmin_obs,300,Norm,N_IM_no_sky,cl_noise_spherex,\n",
    "                              ell_bin_max,par_Ha,nw,2,use_cut=True,cut=np.arange(nw,2*nw))\n",
    "    sigma2_IM_HI_Ha=np.linalg.inv(fisher_IM_HI_Ha)\n",
    "    print('sigma :','Marginal','Conditional')\n",
    "    for i in range(len(par_Ha)):\n",
    "        sig_epsISW_IM_HI_Ha=np.sqrt(sigma2_IM_HI_Ha[i,i])\n",
    "        print(par_Ha[i]+':',sig_epsISW_IM_HI_Ha,',',np.sqrt(1/fisher_IM_HI_Ha[i,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MT SKA SPHEREx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fsky in f_sky:\n",
    "    print('Sky Area:', fsky)\n",
    "    lmin_obs=int(np.pi/np.sqrt(4*np.pi*fsky))+1\n",
    "    fisher_IM_HI_Ha=fisher_fsky_l(Cls_ISW_HI_Halpha,fsky,lmin_obs,300,Norm,N_IM_no_sky,cl_noise_spherex,\n",
    "                              ell_bin_max,pars,nw,2,noise_level=1)\n",
    "    sigma2_IM_HI_Ha=np.linalg.inv(fisher_IM_HI_Ha)#+prior)\n",
    "    print('sigma :','Marginal','Conditional')\n",
    "    for i in range(len(pars)):\n",
    "        sig_epsISW_IM_HI_Ha=np.sqrt(sigma2_IM_HI_Ha[i,i])\n",
    "        print(pars[i]+':',sig_epsISW_IM_HI_Ha,',',np.sqrt(1/fisher_IM_HI_Ha[i,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noiseless regime\n",
    "for fsky in f_sky:\n",
    "    print('Sky Area:', fsky)\n",
    "    lmin_obs=int(np.pi/np.sqrt(4*np.pi*fsky))+1\n",
    "    fisher_IM_HI_Ha=fisher_fsky_l(Cls_ISW_HI_Halpha,fsky,lmin_obs,300,Norm,N_IM_no_sky,cl_noise_spherex,\n",
    "                              ell_bin_max,pars,nw,2,noise_level=0)\n",
    "    sigma2_IM_HI_Ha=np.linalg.inv(fisher_IM_HI_Ha)#+prior)\n",
    "    print('sigma :','Marginal','Conditional')\n",
    "    for i in range(len(pars)):\n",
    "        sig_epsISW_IM_HI_Ha=np.sqrt(sigma2_IM_HI_Ha[i,i])\n",
    "        print(pars[i]+':',sig_epsISW_IM_HI_Ha,',',np.sqrt(1/fisher_IM_HI_Ha[i,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of varying the noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pars_gr=[r'$f_{\\rm NL}$',r'$\\varepsilon_{\\rm ISW}$',r'$\\varepsilon_{\\rm Doppler}$',r'$\\varepsilon_{\\rm SW}$']\n",
    "lmin_obs=int(np.pi/np.sqrt(4*np.pi*0.5))+1\n",
    "noise_per=np.arange(-4,1.1,0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_75=np.zeros((5,len(noise_per)))\n",
    "for i in range(len(noise_per)):\n",
    "    print(noise_per[i])\n",
    "    fisher_IM_HI_Ha=fisher_fsky_l(Cls_ISW_HI_Halpha,0.75,lmin_obs,300,Norm,N_IM_no_sky,cl_noise_spherex,\n",
    "                              ell_bin_max,pars,nw,2,noise_level=10**noise_per[i])\n",
    "    sigma2_IM_HI_Ha=np.linalg.inv(fisher_IM_HI_Ha)\n",
    "    sigmas_75[:,i]=np.sqrt(np.diagonal(sigma2_IM_HI_Ha[6:11,6:11]))\n",
    "    \n",
    "np.savetxt('gr_pars_noise_dz01.dat',sigmas_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_gr=[r'$f_{\\rm NL}$',r'$\\varepsilon_{\\rm ISW}$',r'$\\varepsilon_{\\rm Doppler}$',r'$\\varepsilon_{\\rm SW}$']\n",
    "colors='mgbr'\n",
    "style=[':','-.','-','--']\n",
    "size_line=[4,3,2,1]\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(4):\n",
    "    plt.plot(10**noise_per,sigmas_75[i,:],color=colors[i],ls=style[i],lw=size_line[i],label=pars_gr[i])\n",
    "plt.axhline(y=1, xmin=0.01, xmax=1, linewidth=0.5, color = 'k')\n",
    "plt.xlabel('Noise Level %',fontsize=14)\n",
    "plt.ylabel(r'$\\sigma$',fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim([4e-3,12])\n",
    "plt.legend(loc=4,frameon=False,fontsize=14,ncol=2)\n",
    "plt.savefig('noise_level_effect_dz01_fsky75.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make contour plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsky=0.75\n",
    "lmin_obs=int(np.pi/np.sqrt(4*np.pi*fsky))+1\n",
    "fisher_IM_HI_Ha=fisher_fsky_l(Cls_ISW_HI_Halpha,0.75,lmin_obs,300,Norm,N_IM_no_sky,cl_noise_spherex,\n",
    "                              ell_bin_max,pars,nw,2)\n",
    "sigma2_IM_HI_Ha=np.linalg.inv(fisher_IM_HI_Ha)\n",
    "sigma2_IM_HI_Ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnl_array=np.arange(-6,6,0.05)\n",
    "eps_array=np.arange(-15,16,0.05)\n",
    "\n",
    "def confidence(x,y,xfid,yfid,F):\n",
    "    #sig2=sp.linalg.det(sp.linalg.inv(F))\n",
    "    pararray=np.array([x,y])\n",
    "    fidarray=np.array([xfid,yfid])\n",
    "    test_vec=pararray-fidarray\n",
    "    #return 1/(2*np.pi*sig2)*np.exp(-(test_vec.dot(F.dot(test_vec.T)))/2)\n",
    "    return test_vec.dot(F.dot(test_vec.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contour_doppler=np.zeros((len(fnl_array),len(eps_array)))\n",
    "contour_isw=np.zeros((len(fnl_array),len(eps_array)))\n",
    "contour_pot=np.zeros((len(fnl_array),len(eps_array)))\n",
    "\n",
    "\n",
    "for i in range(len(fnl_array)):\n",
    "    for j in range(len(eps_array)):\n",
    "        contour_isw[i,j]=confidence(fnl_array[i],eps_array[j],0,1,np.linalg.inv(sigma2_IM_HI_Ha[[6,7],:][:,[6,7]]))\n",
    "        contour_pot[i,j]=confidence(fnl_array[i],eps_array[j],0,1,np.linalg.inv(sigma2_IM_HI_Ha[[6,9],:][:,[6,9]]))\n",
    "        contour_doppler[i,j]=confidence(fnl_array[i],eps_array[j],0,1,np.linalg.inv(sigma2_IM_HI_Ha[[6,8],:][:,[6,8]]))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.contour(fnl_array, eps_array,contour_isw.T,colors='g',levels=[2.3,6.17],linewidths=(3,1),linestyles='-')\n",
    "plt.contour(fnl_array, eps_array,contour_doppler.T,colors='b',levels=[2.3,6.17],linewidths=(3,1),linestyles='-.')\n",
    "plt.contour(fnl_array, eps_array,contour_pot.T,colors='r',levels=[2.3,6.17],linewidths=(3,1),linestyles='--')\n",
    "plt.xlabel(r'$f_{\\rm NL}$',fontsize=14)\n",
    "plt.ylabel(r'$\\varepsilon$',fontsize=14)\n",
    "plt.plot(0,1,'k+',ms=10)\n",
    "cores='gbr'\n",
    "import matplotlib.lines as mlines\n",
    "eps_line=[]\n",
    "style=['-','-.','--']\n",
    "for i in range(3):\n",
    "    eps_line.append(mlines.Line2D([], [], color=cores[i],label=pars_gr[i+1],linestyle=style[i],lw=3))\n",
    "    #plt.legend(handles=[eps_line],loc=2)\n",
    "first_legend=plt.legend(handles=eps_line[:],loc=8,fontsize=16,ncol=3)\n",
    "plt.gca().add_artist(first_legend)\n",
    "sig_line=[]\n",
    "sig_label=[r'$1-\\sigma$',r'$2-\\sigma$']\n",
    "for i in range(2):\n",
    "    sig_line.append(mlines.Line2D([], [], color='k',label=sig_label[i],linewidth=[3,1][i]))\n",
    "plt.legend(handles=sig_line[:],loc=9,frameon=False,fontsize=12,ncol=2)\n",
    "plt.ylim([-4,5])\n",
    "plt.xlim([-3.5,3.5])\n",
    "plt.savefig('onesigma_fnl_eps_dz01_compaxis.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
